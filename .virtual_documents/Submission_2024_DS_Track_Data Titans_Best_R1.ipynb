from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = 'all'





import pandas as pd
import numpy as np
from tqdm import tqdm
tqdm.pandas()


## Pandas Display options
pd.set_option('display.max_columns',0)
pd.set_option('display.max_colwidth',0)





## Reading relevant data
match_lvl_data = pd.read_csv('match_level_scorecard.csv')
batsman_lvl_data = pd.read_csv('batsman_level_scorecard.csv')
bowler_lvl_data = pd.read_csv('bowler_level_scorecard.csv')
train_data = pd.read_csv('train_data_with_samplefeatures.csv')
test_data = pd.read_csv('test_data_with_samplefeatures.csv')





## Check Null Values
##Check features with nan value
train_data.isnull().sum()


train_data.describe()





train_data.shape
train_data.head(2)


test_data.shape
test_data.head(2)


match_lvl_data.shape
match_lvl_data.head(2)


batsman_lvl_data.shape
batsman_lvl_data.head(2)


bowler_lvl_data.shape
bowler_lvl_data.head(2)





## Creating a binary winner column - 0 if team1 wins, else 1
train_data['winner_01'] = train_data.apply(lambda x: 1 if (x['team2']==x['winner']) else 0, axis=1)





## Toss winner to numerical - 1 if team2 wins, else 0

train_data['toss_winner_01'] = np.where(train_data['toss winner']==train_data['team2'], 1, 0)
test_data['toss_winner_01'] = np.where(test_data['toss winner']==test_data['team2'], 1, 0)


## Toss decision - categorical - 1 if winner bats, 0 otherwise

train_data['toss_decision_01'] = np.where(train_data['toss decision']=='bat', 1, 0)
test_data['toss_decision_01'] = np.where(test_data['toss decision']=='bat', 1, 0)


# ## Code to plot RnP

from matplotlib import pyplot as plt
import seaborn as sns

sns.set()
import re

def createRnP(X_12, feature, N=5, ylim_lb=0.3, ylim_ub=0.7):
    
    df = X_12.copy()
    df[f'{feature}_bin'] = df[feature].rank(pct=True)//(1/N) # divide feature values for all games in 5 equi-volume buckets.
    df['count'] = 1
    df['team1_win%'] = df['winner_01'].apply(lambda x: 1-x) # invert winner_01 to get team1 winner indicator
    df['team2_win%'] = df['winner_01'].copy()
    df[f'{feature}_min'] = df[feature].copy()
    df[f'{feature}_max'] = df[feature].copy()
    df_g = df.groupby(f'{feature}_bin').agg({'team1_win%':'mean', 'team2_win%':'mean', 'count':'sum', f'{feature}_min':'min',\
                                            f'{feature}_max':'max'}).reset_index()
    N = min(N,df_g.shape[0])
    blue_bar = df_g['team1_win%'].values.tolist()
    ind = np.arange(N)
    # plotting starts
    plt.figure(figsize=(10,5));
    plt.bar(ind, blue_bar, label='Team 1 win%');
    plt.axhline(y=0.5, linewidth=0.5, color='k', linestyle = '--')
    xlabel = re.sub('team_','ratio_',feature)
    plt.xlabel(f'{xlabel} (team1 / team2) bins');
    plt.ylabel('Win %');
    plt.title(f'RnP - {feature} vs win');
    df_g['xticks'] = df_g.apply(lambda x: str(round(x[f'{feature}_min'],2)) + ' - ' + str(round(x[f'{feature}_max'],2)), axis=1)
    plt.xticks(ind, df_g['xticks']);
    plt.ylim([ylim_lb,ylim_ub]);
    plt.legend(loc='best');
    x2,x1 = blue_bar[-1],blue_bar[0]
    slope = x2/x1
    if slope < 1:
        slope = 1/slope
        x1,x2 = x2,x1
    print('slope:', round(x2,2),'/',round(x1,2), '= ',round(slope,2))
    plt.show();


# #### Helper function

def giveLastNgamesPlayer(player_id, date, n, bat_or_bowl):
    
    if bat_or_bowl == 'bat':
        df_topick = batsman_lvl_data
        id_col = 'batsman_id'
    else:
        df_topick = bowler_lvl_data
        id_col = 'bowler_id'
        
    return df_topick[(df_topick['match_dt']<date)&(df_topick[id_col]==float(player_id))]\
                .sort_values(by='match_dt', ascending=False).head(n)


def get_last_5_matches(team_id, match2, match_date):
    team_matches = match2[((match2['team1_id'] == team_id) | (match2['team2_id'] == team_id)) & (match2['match_dt'] < match_date)]
    team_matches = team_matches.sort_values(by='match_dt', ascending=False).head(5)
    return team_matches['match id'].tolist()


matches=match_lvl_data


# Sort the matches by date
matches = matches.sort_values(by='match_dt')


percentage_first_match_win = []
teams = pd.concat([matches['team1_id'], matches['team2_id']]).unique()

for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    team1_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    if (len(team1_matches) == 0) or (len(team2_matches) == 0):
        matches_mod = matches[matches['match_dt'] < match_date].copy()
        results = []
        
        for team in teams:
            team_matches = matches_mod.loc[(matches_mod['team1_id'] == team) | (matches_mod['team2_id'] == team)]
            
            if not team_matches.empty:
                first_match = team_matches.iloc[0]
                
                # Determine the result of the first match
                if first_match['winner_id'] == team:
                    results.append(1)
                else:
                    results.append(0)
        
        # Calculate the percentage of teams that won their first match
        if results:
            percentage_won_first_match = sum(results) / len(results)
        else:
            percentage_won_first_match = 0
        
        percentage_first_match_win.append(percentage_won_first_match)
    else:
        percentage_first_match_win.append(0)


# Add the new column to the train_data
train_data['percent_won_first_match'] = percentage_first_match_win


x=train_data[train_data['percent_won_first_match']!=0]


x


percentage_first_match_win = []
teams = pd.concat([matches['team1_id'], matches['team2_id']]).unique()

for index, row in test_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    team1_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    if (len(team1_matches) == 0) or (len(team2_matches) == 0):
        matches_mod = matches[matches['match_dt'] < match_date].copy()
        results = []
        
        for team in teams:
            team_matches = matches_mod.loc[(matches_mod['team1_id'] == team) | (matches_mod['team2_id'] == team)]
            
            if not team_matches.empty:
                first_match = team_matches.iloc[0]
                
                # Determine the result of the first match
                if first_match['winner_id'] == team:
                    results.append(1)
                else:
                    results.append(0)
        
        # Calculate the percentage of teams that won their first match
        if results:
            percentage_won_first_match = sum(results) / len(results)
        else:
            percentage_won_first_match = 0
        
        percentage_first_match_win.append(percentage_won_first_match)
    else:
        percentage_first_match_win.append(0)


# Add the new column to the train_data
test_data['percent_won_first_match'] = percentage_first_match_win





## derived feature computed using toss winner & toss decision to denote the inning team1 bats.
# If team1 won the toss and chose to bat or team2 won the toss and chose to bowl, the feature takes the value 1, else 2.
match_lvl_data['team1_bat_inning'] = np.where( ((match_lvl_data['team1']==match_lvl_data['toss winner'])&(match_lvl_data['toss decision']=='bat'))|\
                                               ((match_lvl_data['team2']==match_lvl_data['toss winner'])&(match_lvl_data['toss decision']=='field')) , 1, 2)


match_lvl_data.head(2)


def teamAvgEconLastn(team_id, date, n):
    
    # filter out games with either team1/2_id as input team_id, match date less than current game's input date, sort desc by date, and top n rows (games) returned
    df_rel = match_lvl_data[(match_lvl_data['match_dt']<date)&\
                      ((match_lvl_data['team1_id']==team_id)|(match_lvl_data['team2_id']==team_id))]\
                        .sort_values(by='match_dt', ascending=False).head(n)
    # combine two dataframes - one where input team is batting first, and another one where input team is batting second.
    # Separate and rename the runs and balls data for consistency
    df_runs = pd.concat([
        df_rel[df_rel['team1_bat_inning'] == 1][['inning2_runs']].rename(columns={'inning2_runs': 'runs'}),
        df_rel[df_rel['team1_bat_inning'] == 2][['inning1_runs']].rename(columns={'inning1_runs': 'runs'})
    ])
    
    df_balls = pd.concat([
        df_rel[df_rel['team1_bat_inning'] == 1][['inning2_balls']].rename(columns={'inning2_balls': 'balls'}),
        df_rel[df_rel['team1_bat_inning'] == 2][['inning1_balls']].rename(columns={'inning1_balls': 'balls'})
    ])
    
    # Combine the runs and balls dataframes
    df_combined = pd.concat([df_runs.reset_index(drop=True), df_balls.reset_index(drop=True)], axis=1)

    # Calculate the average economy rate (runs per ball)
    df_combined['avgEcon'] = df_combined['runs'] / df_combined['balls']

    # Return the mean of the average economy rate
    return df_combined['avgEcon'].mean() 


# Computing average Economy in last 10 games for team1 for train dataset.
train_data['team1_avg_Econ_last10'] = train_data.progress_apply(lambda x: \
            teamAvgEconLastn(x['team1_id'], x['match_dt'], 10), axis=1)
# Computing average Economy in last 10 games for team2 for train dataset.
train_data['team2_avg_Econ_last10'] = train_data.progress_apply(lambda x: \
            teamAvgEconLastn(x['team2_id'], x['match_dt'], 10), axis=1)


# Taking ratio of (average Economy in last 10 games for team1) to (average Economy in last 10 games for team2). Adding 1 to handle divide by zero exceptions.
train_data['team_avg_Econ_last10'] = (train_data['team1_avg_Econ_last10']+1)/(train_data['team2_avg_Econ_last10']+1)
train_data.drop(columns=['team1_avg_Econ_last10','team2_avg_Econ_last10'], inplace=True) # dropping intermediate columns


train_data.shape
train_data.tail(2)


# RnP of team_avg_Econ_last10 computed over the train data. Slope denotes ratio of right most bin to left most bin.
createRnP(train_data, 'team_avg_Econ_last10')


## Doing similar process for test dataset

test_data['team1_avg_Econ_last10'] = test_data.progress_apply(lambda x: \
            teamAvgEconLastn(x['team1_id'], x['match_dt'], 10), axis=1)
test_data['team2_avg_Econ_last10'] = test_data.progress_apply(lambda x: \
            teamAvgEconLastn(x['team2_id'], x['match_dt'], 10), axis=1)
test_data['team_avg_Econ_last10'] = (test_data['team1_avg_Econ_last10']+1)/(test_data['team2_avg_Econ_last10']+1)
test_data.drop(columns=['team1_avg_Econ_last10','team2_avg_Econ_last10'], inplace=True) # dropping intermediate columns
test_data.shape
test_data.head(2)





def get_last_10_matches(team_id, match2, match_date):
    team_matches = match2[((match2['team1_id'] == team_id) | (match2['team2_id'] == team_id)) & (match2['match_dt'] < match_date)]
    team_matches = team_matches.sort_values(by='match_dt', ascending=False).head(10)
    return team_matches['match id'].tolist()


def srT3Lastn(player_list, date, n):
    player_list = str(player_list).split(':')  # split string of ':' separated ids into a list of ids
    strike_rate_list = []
    
    for player in player_list:  # loop over each player_id in roster
        df_rel = giveLastNgamesPlayer(player_id=player, date=date, n=n, bat_or_bowl='bat')  # getting batting stats from last n games for each player
        total_runs = np.nansum(df_rel['runs'])  # Sum up number of runs for the player
        total_balls_faced = np.nansum(df_rel['balls_faced'])  # Sum up number of balls faced for the player
        strike_rate = (total_runs / total_balls_faced) * 100 if total_balls_faced > 0 else 0  # Calculate strike rate
        
        strike_rate_list.append((player, strike_rate, total_balls_faced))  # Append the player id, strike rate, and total balls faced as a tuple to the list
    
    # Sort the list by strike rate in descending order and take the top 3
    top_3_batsmen = sorted(strike_rate_list, key=lambda x: x[1], reverse=True)[:3]
    
    weighted_sr_list = []
    total_balls_top_3 = sum([batsman[2] for batsman in top_3_batsmen])  # Sum up the total balls faced by top 3 batsmen
    
    if total_balls_top_3 > 0:  # Ensure no division by zero
        for batsman in top_3_batsmen:
            weighted_sr_list.append(batsman[1] * (batsman[2] / total_balls_top_3))  # Weighted strike rate contribution
    
    return sum(weighted_sr_list) if top_3_batsmen else 0


# Applying the function to compute the number of wickets taken by top 3 bowlers for team1 and team2

tqdm.pandas() # to use progress_apply

# Training dataset
train_data['team1_srrate_top3_last10'] = train_data.progress_apply(lambda x: \
            srT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
train_data['team2_srrate_top3_last10'] = train_data.progress_apply(lambda x: \
            srT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)


# Calculating the ratio of wickets taken by top 3 bowlers of team1 to team2
train_data['team_srrate_ratio_last10'] = (train_data['team1_srrate_top3_last10'] + 1) / (train_data['team2_srrate_top3_last10'] + 1)
# Dropping intermediate columns
train_data.drop(columns=['team1_srrate_top3_last10', 'team2_srrate_top3_last10'], inplace=True)


train_data.head()


# RnP of team_count_50runs_last15 computed over the train data. Slope denotes ratio of right most bin to left most bin.
createRnP(train_data, 'team_srrate_ratio_last10')


## Doing similar process for test dataset

test_data['team1_srrate_top3_last10'] = test_data.progress_apply(lambda x: \
            srT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
test_data['team2_srrate_top3_last10'] = test_data.progress_apply(lambda x: \
            srT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)

# Calculating the ratio of wickets taken by top 3 bowlers of team1 to team2
test_data['team_srrate_ratio_last10'] = (test_data['team1_srrate_top3_last10'] + 1) / (test_data['team2_srrate_top3_last10'] + 1)

# Dropping intermediate columns
test_data.drop(columns=['team1_srrate_top3_last10', 'team2_srrate_top3_last10'], inplace=True)


test_data.head()





def runsT3Lastn(player_list, date, n):
    
    player_list = str(player_list).split(':') # split string of ':' separated ids into a list of ids
    runs_list = []
    
    for player in player_list: # loop over each player_id in roster
        df_rel = giveLastNgamesPlayer(player_id=player, date=date, n=n, bat_or_bowl='bat') # getting bowling stats from last n games for each player
        total_runs = np.nansum(df_rel['runs']) # Sum up number of runs for the player
        runs_list.append((player, total_runs)) # Append the player id and total wickets as a tuple to the list
    
    # Sort the list by total runs in descending order and take the top 3
    top_3_batsmen = sorted(runs_list, key=lambda x: x[1], reverse=True)[:3]
    
    # Sum up the runs taken by the top 3 bowlers
    total_runs_top_3 = sum([batsman[1] for batsman in top_3_batsmen])
    
    return total_runs_top_3


# Applying the function to compute the number of wickets taken by top 3 bowlers for team1 and team2

tqdm.pandas() # to use progress_apply

# Training dataset
train_data['team1_runs_top3_last10'] = train_data.progress_apply(lambda x: \
            runsT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
train_data['team2_runs_top3_last10'] = train_data.progress_apply(lambda x: \
            runsT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)


# Calculating the ratio of wickets taken by top 3 bowlers of team1 to team2
train_data['team_runs_ratio_last10'] = (train_data['team1_runs_top3_last10'] + 1) / (train_data['team2_runs_top3_last10'] + 1)
# Dropping intermediate columns
train_data.drop(columns=['team1_runs_top3_last10', 'team2_runs_top3_last10'], inplace=True)


train_data.head()


# RnP of team_count_50runs_last15 computed over the train data. Slope denotes ratio of right most bin to left most bin.
createRnP(train_data, 'team_runs_ratio_last10')


train_data.head()


## Doing similar process for test dataset

test_data['team1_runs_top3_last10'] = test_data.progress_apply(lambda x: \
            runsT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
test_data['team2_runs_top3_last10'] = test_data.progress_apply(lambda x: \
            runsT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)

# Calculating the ratio of wickets taken by top 3 bowlers of team1 to team2
test_data['team_runs_ratio_last10'] = (test_data['team1_runs_top3_last10'] + 1) / (test_data['team2_runs_top3_last10'] + 1)

# Dropping intermediate columns
test_data.drop(columns=['team1_runs_top3_last10', 'team2_runs_top3_last10'], inplace=True)


test_data.head()





def get_last_5_matches(team_id, match2, match_date):
    team_matches = match2[((match2['team1_id'] == team_id) | (match2['team2_id'] == team_id)) & (match2['match_dt'] < match_date)]
    team_matches = team_matches.sort_values(by='match_dt', ascending=False).head(5)
    return team_matches['match id'].tolist()


train_data_new1=train_data
test_data_new1=test_data


## Toss winner to numerical - 1 if team2 wins, else 0

match_lvl_data['toss_winner_01'] = np.where(match_lvl_data['toss winner']==match_lvl_data['team2'], 1, 0)


## Toss decision - categorical - 1 if winner bats, 0 otherwise

match_lvl_data['toss_decision_01'] = np.where(match_lvl_data['toss decision']=='bat', 1, 0)


def calculate_team_dot_balls_bowled(match_id, team_id, bowler_df, train_df):
    match_data = train_df[train_df['match id'] == match_id]
    
    if len(match_data) == 0:
        print(f"No match data found for Match ID: {match_id}")
        return 0
    if match_data.iloc[0]['team1_id'] == team_id:
        if match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==1 :
            balls_bowled=match_data.iloc[0]['inning2_balls']
        elif match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==0 :
            balls_bowled=match_data.iloc[0]['inning1_balls']
        elif match_data.iloc[0]['toss_winner_01']==1 and match_data.iloc[0]['toss_decision_01']==0 :
            balls_bowled=match_data.iloc[0]['inning1_balls']
        else:
            balls_bowled=match_data.iloc[0]['inning2_balls']
        team_roster_ids = match_data.iloc[0]['team1_roster_ids'].split(':')
    elif match_data.iloc[0]['team2_id'] == team_id:
        if match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==1 :
            balls_bowled=match_data.iloc[0]['inning1_balls']
        elif match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==0 :
            balls_bowled=match_data.iloc[0]['inning2_balls']
        elif match_data.iloc[0]['toss_winner_01']==1 and match_data.iloc[0]['toss_decision_01']==0 :
            balls_bowled=match_data.iloc[0]['inning2_balls']
        else:
            balls_bowled=match_data.iloc[0]['inning1_balls']
        team_roster_ids = match_data.iloc[0]['team2_roster_ids'].split(':')
    else:
        print(f"Team ID {team_id} not found in Match ID {match_id}")
        return 0
    team_roster_ids = [id.split('.')[0] for id in team_roster_ids]
    
    match_bowler_data = bowler_df[bowler_df['match id'] == match_id].copy()
    match_bowler_data['bowler_id'] = match_bowler_data['bowler_id'].astype(str)
    match_bowler_data['bowler_id'] = match_bowler_data['bowler_id'].apply(lambda x: x.split('.')[0])  
    team_bowlers = match_bowler_data[match_bowler_data['bowler_id'].isin(team_roster_ids)]
    dot_balls_bowled = team_bowlers['dots'].sum()
    percentage_dot_balls_bowled=dot_balls_bowled/balls_bowled
    
    return percentage_dot_balls_bowled*100


percentage_dot_balls_ratio = []
for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_5_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_last_5_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    team1_percentage_dotballs_bowled = []
    team2_percentage_dotballs_bowled = []

    for match in team1_last_5_matches:
        team1_percentage_dotballs_bowled.append(calculate_team_dot_balls_bowled(match, team1_id, bowler_lvl_data, match_lvl_data ))
    for match in team2_last_5_matches:
        team2_percentage_dotballs_bowled.append(calculate_team_dot_balls_bowled(match, team2_id, bowler_lvl_data, match_lvl_data ))
    if len(team1_last_5_matches) == 0 or len(team2_last_5_matches) == 0:
        percentage_dot_balls_ratio.append(np.nan)
        continue
    else:
        percentage_dot_balls_ratio.append(((sum(team1_percentage_dotballs_bowled)/len(team1_last_5_matches))+1)/((sum(team2_percentage_dotballs_bowled)/len(team2_last_5_matches))+1))


train_data['percentage_dot_balls_bowled_last_5']=percentage_dot_balls_ratio


train_data.head()


percentage_dot_balls_ratio = []
for index, row in test_data_new1.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_5_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_last_5_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    team1_percentage_dotballs_bowled = []
    team2_percentage_dotballs_bowled = []

    for match in team1_last_5_matches:
        team1_percentage_dotballs_bowled.append(calculate_team_dot_balls_bowled(match, team1_id, bowler_lvl_data, match_lvl_data ))
    for match in team2_last_5_matches:
        team2_percentage_dotballs_bowled.append(calculate_team_dot_balls_bowled(match, team2_id, bowler_lvl_data, match_lvl_data ))
    if len(team1_last_5_matches) == 0 or len(team2_last_5_matches) == 0:
        percentage_dot_balls_ratio.append(np.nan)
        continue
    else:
        percentage_dot_balls_ratio.append(((sum(team1_percentage_dotballs_bowled)/len(team1_last_5_matches))+1)/((sum(team2_percentage_dotballs_bowled)/len(team2_last_5_matches))+1))


test_data['percentage_dot_balls_bowled_last_5']=percentage_dot_balls_ratio


test_data.head()


# RnP of team_avg_Econ_last10 computed over the train data. Slope denotes ratio of right most bin to left most bin.
createRnP(train_data, 'percentage_dot_balls_bowled_last_5')





match_lvl_data['toss_winner_01'] = (match_lvl_data['toss winner'] == match_lvl_data['team2']).astype(int)
match_lvl_data['toss_decision_01'] = (match_lvl_data['toss decision'] == 'bat').astype(int)
match_lvl_data['winner_01'] = (match_lvl_data['winner'] == match_lvl_data['team2']).astype(int)


match_lvl_data.sample()


def pitch_condn(ground_id, date, team1_bat_inning):
    
    # filter out games with either team1/2_id as input ground_id, match date less than current game's input date, sort desc by date, and top n rows (games) returned
    df = match_lvl_data[(match_lvl_data['match_dt']<date)].sort_values(by='match_dt', ascending=False)
    df_rel = df[df['ground_id'] == ground_id] 
    df_rel['chase_win'] = np.where(
        (((df_rel['toss_winner_01'] == 1) & (df_rel['toss_decision_01'] == 0)) | ((df_rel['toss_winner_01'] == 0) & (df_rel['toss_decision_01'] == 1))) & (df_rel['winner_01'] == 0),
        0,
        np.where(
            (((df_rel['toss_winner_01'] == 1) & (df_rel['toss_decision_01'] == 1)) | ((df_rel['toss_winner_01'] == 0) & (df_rel['toss_decision_01'] == 0))) & (df_rel['winner_01'] == 1),
            0,
            1
        )
    )
    
    if(df_rel.shape[0] != 0):
        if(team1_bat_inning == 2):
            return sum(df_rel['chase_win'])/df_rel.shape[0]
        else:
            return 1-(sum(df_rel['chase_win'])/df_rel.shape[0])
    else:
        return float('nan')


match_lvl_data[match_lvl_data['ground_id'] == 1469]


train_data['team1_bat_inning'] = np.where( ((train_data['team1']==train_data['toss winner'])&(train_data['toss decision']=='bat'))|\
                                        ((train_data['team2']==train_data['toss winner'])&(train_data['toss decision']=='field')) , 1, 2)
train_data['pitch condition'] = train_data.progress_apply(lambda x: \
            pitch_condn(x['ground_id'], x['match_dt'], x['team1_bat_inning']), axis=1)


train_data['pitch condition'].sample(5)


createRnP(train_data, 'pitch condition')


## Doing similar process for test dataset

test_data['team1_avg_Econ_last10'] = test_data.progress_apply(lambda x: \
            teamAvgEconLastn(x['team1_id'], x['match_dt'], 10), axis=1)
test_data['team2_avg_Econ_last10'] = test_data.progress_apply(lambda x: \
            teamAvgEconLastn(x['team2_id'], x['match_dt'], 10), axis=1)
test_data['team_avg_Econ_last10'] = (test_data['team1_avg_Econ_last10']+1)/(test_data['team2_avg_Econ_last10']+1)
test_data.drop(columns=['team1_avg_Econ_last10','team2_avg_Econ_last10'], inplace=True) # dropping intermediate columns
test_data['team1_bat_inning'] = np.where( ((test_data['team1']==test_data['toss winner'])&(test_data['toss decision']=='bat'))|\
                                        ((test_data['team2']==test_data['toss winner'])&(test_data['toss decision']=='field')) , 1, 2)
test_data['pitch condition'] = test_data.progress_apply(lambda x: \
            pitch_condn(x['ground_id'], x['match_dt'], x['team1_bat_inning']), axis=1)
test_data.shape
test_data.head(2)


test_data['pitch condition']





def noWsT3Lastn(player_list, date, n):
    
    player_list = str(player_list).split(':') # split string of ':' separated ids into a list of ids
    wickets_list = []
    
    for player in player_list: # loop over each player_id in roster
        df_rel = giveLastNgamesPlayer(player_id=player, date=date, n=n, bat_or_bowl='bowl') # getting bowling stats from last n games for each player
        total_wickets = np.nansum(df_rel['wicket_count']) # Sum up number of wickets for the player
        wickets_list.append((player, total_wickets)) # Append the player id and total wickets as a tuple to the list
    
    # Sort the list by total wickets in descending order and take the top 3
    top_3_bowlers = sorted(wickets_list, key=lambda x: x[1], reverse=True)[:3]
    
    # Sum up the wickets taken by the top 3 bowlers
    total_wickets_top_3 = sum([w[1] for w in top_3_bowlers])
    
    return total_wickets_top_3


# Applying the function to compute the number of wickets taken by top 3 bowlers for team1 and team2

tqdm.pandas() # to use progress_apply

# Training dataset
train_data['team1_wickets_top3_last10'] = train_data.progress_apply(lambda x: \
            noWsT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
train_data['team2_wickets_top3_last10'] = train_data.progress_apply(lambda x: \
            noWsT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)


# Calculating the ratio of wickets taken by top 3 bowlers of team1 to team2
train_data['team_wickets_ratio_last10'] = (train_data['team1_wickets_top3_last10'] + 1) / (train_data['team2_wickets_top3_last10'] + 1)
# Dropping intermediate columns
train_data.drop(columns=['team1_wickets_top3_last10', 'team2_wickets_top3_last10'], inplace=True)


train_data.shape
train_data.tail(2)


# RnP of team_count_50runs_last15 computed over the train data. Slope denotes ratio of right most bin to left most bin.
createRnP(train_data, 'team_wickets_ratio_last10')


## Doing similar process for test dataset

test_data['team1_wickets_top3_last10'] = test_data.progress_apply(lambda x: \
            noWsT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
test_data['team2_wickets_top3_last10'] = test_data.progress_apply(lambda x: \
            noWsT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)

# Calculating the ratio of wickets taken by top 3 bowlers of team1 to team2
test_data['team_wickets_ratio_last10'] = (test_data['team1_wickets_top3_last10'] + 1) / (test_data['team2_wickets_top3_last10'] + 1)

# Dropping intermediate columns
test_data.drop(columns=['team1_wickets_top3_last10', 'team2_wickets_top3_last10'], inplace=True)


test_data.shape
test_data.head(2)





def percentage_runs_through_boundaries(match_id, team_id, batsman_df, train_df):
    match_data = train_df[train_df['match id'] == match_id]
    
    if len(match_data) == 0:
        print(f"No match data found for Match ID: {match_id}")
        return 0
    
    if match_data.iloc[0]['team1_id'] == team_id:
        if match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==1 :
            runs_scored=match_data.iloc[0]['inning1_runs']
        elif match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==0 :
            runs_scored=match_data.iloc[0]['inning2_runs']
        elif match_data.iloc[0]['toss_winner_01']==1 and match_data.iloc[0]['toss_decision_01']==0 :
            runs_scored=match_data.iloc[0]['inning2_runs']
        else:
            runs_scored=match_data.iloc[0]['inning1_runs']
        team_roster_ids = match_data.iloc[0]['team1_roster_ids'].split(':')
    elif match_data.iloc[0]['team2_id'] == team_id:
        if match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==1 :
            runs_scored=match_data.iloc[0]['inning2_runs']
        elif match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==0 :
            runs_scored=match_data.iloc[0]['inning1_runs']
        elif match_data.iloc[0]['toss_winner_01']==1 and match_data.iloc[0]['toss_decision_01']==0 :
            runs_scored=match_data.iloc[0]['inning1_runs']
        else:
            runs_scored=match_data.iloc[0]['inning2_runs']
        team_roster_ids = match_data.iloc[0]['team2_roster_ids'].split(':')
    else:
        print(f"Team ID {team_id} not found in Match ID {match_id}")
        return 0
    
    team_roster_ids = [id.split('.')[0] for id in team_roster_ids]
    
    match_batsman_data = batsman_df[batsman_df['match id'] == match_id].copy()
    match_batsman_data['batsman_id'] = match_batsman_data['batsman_id'].astype(str).apply(lambda x: x.split('.')[0])
    
    team_batsmen = match_batsman_data[match_batsman_data['batsman_id'].isin(team_roster_ids)].copy()
    
    team_batsmen.loc[:, 'Fours'] = team_batsmen['Fours'].fillna(0)
    team_batsmen.loc[:, 'Sixes'] = team_batsmen['Sixes'].fillna(0)
    
    runs_through_boundaries = 4 * team_batsmen['Fours'].sum() + 6 * team_batsmen['Sixes'].sum()
    percentage_runs_through_boundaries=runs_through_boundaries/runs_scored
    
    return percentage_runs_through_boundaries*100


train_data_new1=train_data
test_data_new1=test_data


## Toss winner to numerical - 1 if team2 wins, else 0

train_data_new1['toss_winner_01'] = np.where(train_data['toss winner']==train_data['team2'], 1, 0)
test_data_new1['toss_winner_01'] = np.where(test_data['toss winner']==test_data['team2'], 1, 0)


## Toss decision - categorical - 1 if winner bats, 0 otherwise

train_data_new1['toss_decision_01'] = np.where(train_data['toss decision']=='bat', 1, 0)
test_data_new1['toss_decision_01'] = np.where(test_data['toss decision']=='bat', 1, 0)


percentage_runs_through_boundaries_ratio = []
for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_5_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_last_5_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    percentage_team1_runs_through_boundaries = []
    percentage_team2_runs_through_boundaries = []

    for match in team1_last_5_matches:
        percentage_team1_runs_through_boundaries.append(percentage_runs_through_boundaries(match, team1_id, batsman_lvl_data, match_lvl_data ))
    for match in team2_last_5_matches:
        percentage_team2_runs_through_boundaries.append(percentage_runs_through_boundaries(match, team2_id, batsman_lvl_data, match_lvl_data ))
    if len(team1_last_5_matches) == 0 or len(team2_last_5_matches) == 0:
        percentage_runs_through_boundaries_ratio .append(np.nan)
        continue
    percentage_runs_through_boundaries_ratio.append(((sum(percentage_team1_runs_through_boundaries)/len(team1_last_5_matches))+1)/((sum(percentage_team2_runs_through_boundaries)/len(team2_last_5_matches))+1))    


train_data['percentage_runs_through_boundaries_last_5_ratio']=percentage_runs_through_boundaries_ratio


train_data.head()


createRnP(train_data, 'percentage_runs_through_boundaries_last_5_ratio')


percentage_runs_through_boundaries_ratio = []
for index, row in test_data_new1.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_5_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_last_5_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    percentage_team1_runs_through_boundaries = []
    percentage_team2_runs_through_boundaries = []

    for match in team1_last_5_matches:
        percentage_team1_runs_through_boundaries.append(percentage_runs_through_boundaries(match, team1_id, batsman_lvl_data, match_lvl_data ))
    for match in team2_last_5_matches:
        percentage_team2_runs_through_boundaries.append(percentage_runs_through_boundaries(match, team2_id, batsman_lvl_data, match_lvl_data ))
    if len(team1_last_5_matches) == 0 or len(team2_last_5_matches) == 0:
        percentage_runs_through_boundaries_ratio .append(np.nan)
        continue
    percentage_runs_through_boundaries_ratio.append(((sum(percentage_team1_runs_through_boundaries)/len(team1_last_5_matches))+1)/((sum(percentage_team2_runs_through_boundaries)/len(team2_last_5_matches))+1))    


test_data['percentage_runs_through_boundaries_last_5_ratio']=percentage_runs_through_boundaries_ratio


test_data.head()





# Function to find the average economy rate of the top 3 bowlers of a team in the last n games
def avgEconsT3Lastn(player_list, date, n):
    
    player_list = str(player_list).split(':') # split string of ':' separated ids into a list of ids
    econ_list = []
    
    for player in player_list: # loop over each player_id in roster
        df_rel = giveLastNgamesPlayer(player_id=player, date=date, n=n, bat_or_bowl='bowl') # getting bowling stats from last n games for each player
        if not df_rel.empty:
            avg_econ = np.nanmean(df_rel['economy']) # Average economy rate for the player
            econ_list.append((player, avg_econ)) # Append the player id and average economy rate as a tuple to the list
    
    # If econ_list is empty, return NaN to indicate no data available
    if not econ_list:
        return np.nan
    
    # Sort the list by average economy rate in ascending order and take the top 3 (lower economy is better)
    top_3_bowlers = sorted(econ_list, key=lambda x: x[1])[:3]
    
    # Calculate the average economy rate of the top 3 bowlers
    avg_econ_top_3 = np.nanmean([e[1] for e in top_3_bowlers])
    
    return avg_econ_top_3


tqdm.pandas() # to use progress_apply

# Training dataset
train_data['team1_avg_econ_top3_last10'] = train_data.progress_apply(lambda x: \
            avgEconsT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
train_data['team2_avg_econ_top3_last10'] = train_data.progress_apply(lambda x: \
            avgEconsT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)


# Calculating the ratio of average economy rates of top 3 bowlers of team1 to team2
train_data['team_avg_econ_ratio_last10'] = (train_data['team1_avg_econ_top3_last10'] + 1) / ((train_data['team2_avg_econ_top3_last10'] + 1)+(train_data['team1_avg_econ_top3_last10'] + 1))
# Dropping intermediate columns
train_data.drop(columns=['team1_avg_econ_top3_last10', 'team2_avg_econ_top3_last10'], inplace=True)


train_data.shape
train_data.tail(2)


# RnP of team_avg_econ_ratio_last10 computed over the train data. Slope denotes ratio of right most bin to left most bin.
createRnP(train_data, 'team_avg_econ_ratio_last10')


# Test dataset
test_data['team1_avg_econ_top3_last10'] = test_data.progress_apply(lambda x: \
            avgEconsT3Lastn(player_list=x['team1_roster_ids'], date=x['match_dt'], n=10), axis=1)
test_data['team2_avg_econ_top3_last10'] = test_data.progress_apply(lambda x: \
            avgEconsT3Lastn(player_list=x['team2_roster_ids'], date=x['match_dt'], n=10), axis=1)


# Calculating the ratio of average economy rates of top 3 bowlers of team1 to team2
test_data['team_avg_econ_ratio_last10'] = (test_data['team1_avg_econ_top3_last10'] + 1) / ((test_data['team2_avg_econ_top3_last10'] + 1)+(test_data['team1_avg_econ_top3_last10'] + 1))

# Dropping intermediate columns
test_data.drop(columns=['team1_avg_econ_top3_last10', 'team2_avg_econ_top3_last10'], inplace=True)


test_data.shape
test_data.head(2)





def extra_runs_given(match_id, team_id, bowler_df, train_df):
    match_data = train_df[train_df['match id'] == match_id]
    
    if len(match_data) == 0:
        print(f"No match data found for Match ID: {match_id}")
        return 0
    
    if match_data.iloc[0]['team1_id'] == team_id:
        team_roster_ids = match_data.iloc[0]['team1_roster_ids'].split(':')
    elif match_data.iloc[0]['team2_id'] == team_id:
        team_roster_ids = match_data.iloc[0]['team2_roster_ids'].split(':')
    else:
        print(f"Team ID {team_id} not found in Match ID {match_id}")
        return 0
    
    team_roster_ids = [id.split('.')[0] for id in team_roster_ids]
    
    match_bowler_data = bowler_df[bowler_df['match id'] == match_id].copy()
    match_bowler_data['bowler_id'] = match_bowler_data['bowler_id'].astype(str).apply(lambda x: x.split('.')[0])
    
    team_bowlers = match_bowler_data[match_bowler_data['bowler_id'].isin(team_roster_ids)].copy()
    
    team_bowlers.loc[:, 'wides'] = team_bowlers['wides'].fillna(0)
    team_bowlers.loc[:, 'noballs'] = team_bowlers['noballs'].fillna(0)
    if len(team_bowlers)<2:
        return 1
    
    runs_through_extras = team_bowlers['wides'].sum() + team_bowlers['noballs'].sum()
    
    return runs_through_extras


runs_through_extras_ratio = []
for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_5_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_last_5_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    team1_runs_through_extras = []
    team2_runs_through_extras = []

    for match in team1_last_5_matches:
        team1_runs_through_extras.append(extra_runs_given(match, team1_id, bowler_lvl_data, match_lvl_data ))
    for match in team2_last_5_matches:
        team2_runs_through_extras.append(extra_runs_given(match, team2_id, bowler_lvl_data, match_lvl_data ))
    if (len(team1_last_5_matches)==0 and len(team2_last_5_matches)==0):
        runs_through_extras_ratio.append(0.5)
        continue
    elif len(team1_last_5_matches) == 0 :
        runs_through_extras_ratio.append(row['percent_won_first_match'])
        continue
    elif (len(team2_last_5_matches) == 0 ):
        runs_through_extras_ratio.append(1-row['percent_won_first_match'])
        continue
    
    runs_through_extras_ratio.append(((sum(team1_runs_through_extras)/len(team1_last_5_matches))*10+1)/(((sum(team2_runs_through_extras)/len(team2_last_5_matches))*10+1)+((sum(team1_runs_through_extras)/len(team1_last_5_matches))*10+1)))


train_data['runs_through_extras_last_5_ratio']=runs_through_extras_ratio


train_data.head()


createRnP(train_data, 'runs_through_extras_last_5_ratio')


runs_through_extras_ratio = []
for index, row in test_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_5_matches = get_last_5_matches(team1_id, match_lvl_data, match_date)
    team2_last_5_matches = get_last_5_matches(team2_id, match_lvl_data, match_date)
    
    team1_runs_through_extras = []
    team2_runs_through_extras = []

    for match in team1_last_5_matches:
        team1_runs_through_extras.append(extra_runs_given(match, team1_id, bowler_lvl_data, match_lvl_data ))
    for match in team2_last_5_matches:
        team2_runs_through_extras.append(extra_runs_given(match, team2_id, bowler_lvl_data, match_lvl_data ))
    if (len(team1_last_5_matches)==0 and len(team2_last_5_matches)==0):
        runs_through_extras_ratio.append(0.5)
        continue
    elif len(team1_last_5_matches) == 0 :
        runs_through_extras_ratio.append(row['percent_won_first_match'])
        continue
    elif (len(team2_last_5_matches) == 0 ):
        runs_through_extras_ratio.append(1-row['percent_won_first_match'])
        continue
    
    runs_through_extras_ratio.append(((sum(team1_runs_through_extras)/len(team1_last_5_matches))*10+1)/(((sum(team2_runs_through_extras)/len(team2_last_5_matches))*10+1)+((sum(team1_runs_through_extras)/len(team1_last_5_matches))*10+1)))    


test_data['runs_through_extras_last_5_ratio']=runs_through_extras_ratio


test_data.head()





def bowling_strike_rate(match_id, team_id, train_df):
    match_data = train_df[train_df['match id'] == match_id]
    
    if len(match_data) == 0:
        print(f"No match data found for Match ID: {match_id}")
        return 0
    
    if match_data.iloc[0]['team1_id'] == team_id:
        if match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==1 :
            if match_data.iloc[0]['inning2_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']/match_data.iloc[0]['inning2_wickets']
        elif match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==0 :
            if match_data.iloc[0]['inning1_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']/match_data.iloc[0]['inning1_wickets']
        elif match_data.iloc[0]['toss_winner_01']==1 and match_data.iloc[0]['toss_decision_01']==0 :
            if match_data.iloc[0]['inning2_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']/match_data.iloc[0]['inning2_wickets']
        else:
            if match_data.iloc[0]['inning1_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']/match_data.iloc[0]['inning1_wickets']
    
    elif match_data.iloc[0]['team2_id'] == team_id:
        if match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==1 :
            if match_data.iloc[0]['inning1_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']/match_data.iloc[0]['inning1_wickets']
        elif match_data.iloc[0]['toss_winner_01']==0 and match_data.iloc[0]['toss_decision_01']==0 :
            if match_data.iloc[0]['inning2_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']/match_data.iloc[0]['inning2_wickets']
        elif match_data.iloc[0]['toss_winner_01']==1 and match_data.iloc[0]['toss_decision_01']==0 :
            if match_data.iloc[0]['inning1_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning1_runs']/match_data.iloc[0]['inning1_wickets']
        else:
            if match_data.iloc[0]['inning2_wickets']==0:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']
            else:
                bowl_strike_rate=match_data.iloc[0]['inning2_runs']/match_data.iloc[0]['inning2_wickets']
       
    else:
        print(f"Team ID {team_id} not found in Match ID {match_id}")
        return 0
    
    return bowl_strike_rate


bowling_strike_rate_ratio = []
for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_10_matches = get_last_10_matches(team1_id, match_lvl_data, match_date)
    team2_last_10_matches = get_last_10_matches(team2_id, match_lvl_data, match_date)
    
    team1_bowling_strike_rate = []
    team2_bowling_strike_rate = []

    for match in team1_last_10_matches:
        team1_bowling_strike_rate.append(bowling_strike_rate(match, team1_id, match_lvl_data))
    for match in team2_last_10_matches:
        team2_bowling_strike_rate.append(bowling_strike_rate(match, team2_id, match_lvl_data))
    if (len(team1_last_5_matches)==0 or len(team2_last_5_matches)==0):
        bowling_strike_rate_ratio.append(np.NaN)
    
    else:
        bowling_strike_rate_ratio.append((((sum(team1_bowling_strike_rate)/len(team1_last_5_matches))+1)/(((sum(team2_bowling_strike_rate)/len(team2_last_5_matches))+1))))    


train_data['bowling_srrate_ratio_last_10']=bowling_strike_rate_ratio


createRnP(train_data, 'bowling_srrate_ratio_last_10')


bowling_strike_rate_ratio = []
for index, row in test_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    
    team1_last_10_matches = get_last_10_matches(team1_id, match_lvl_data, match_date)
    team2_last_10_matches = get_last_10_matches(team2_id, match_lvl_data, match_date)
    
    team1_bowling_strike_rate = []
    team2_bowling_strike_rate = []

    for match in team1_last_10_matches:
        team1_bowling_strike_rate.append(bowling_strike_rate(match, team1_id, match_lvl_data))
    for match in team2_last_10_matches:
        team2_bowling_strike_rate.append(bowling_strike_rate(match, team2_id, match_lvl_data))
    if (len(team1_last_5_matches)==0 or len(team2_last_5_matches)==0):
        bowling_strike_rate_ratio.append(np.NaN)
    
    else:
        bowling_strike_rate_ratio.append((((sum(team1_bowling_strike_rate)/len(team1_last_5_matches))+1)/(((sum(team2_bowling_strike_rate)/len(team2_last_5_matches))+1))))    


test_data['bowling_srrate_ratio_last_10']=bowling_strike_rate_ratio





def wins(date, team_id):
    
    # filter out games with either team1/2_id as input ground_id, match date less than current game's input date, sort desc by date, and top n rows (games) returned
    df = match_lvl_data[(match_lvl_data['match_dt']<date)].sort_values(by='match_dt', ascending=False)
    df_rel1 = df[df['team1_id'] == team_id] 
    df_rel2 = df[df['team2_id'] == team_id]
    df_rel =  pd.concat([df_rel1, df_rel2], axis = 0)
    if(df_rel.shape[0] == 0):
        return float('nan')
    df1 = df_rel[df_rel['by'] == 'wickets']
    df2 = df_rel[df_rel['by'] == 'runs']
    df1['win amount'] = (df1['win amount']/df1['win amount'].max())
    df2['win amount'] = (df2['win amount']/df2['win amount'].max()) 
    final_df = pd.concat([df1, df2], axis = 0)
    return final_df['win amount'].sum() / final_df.shape[0]


train_data['weighted wins'] = train_data.progress_apply(lambda x: \
            (wins(x['match_dt'], x['team1_id'])/wins(x['match_dt'], x['team2_id'])), axis=1)


test_data['weighted wins'] = test_data.progress_apply(lambda x: \
            (wins(x['match_dt'], x['team1_id'])/wins(x['match_dt'], x['team2_id'])), axis=1)


createRnP(train_data, 'weighted wins')





def get_last_5_matches_with_lighting(team_id, match_date, lighting_condition, match2):
    team_matches = match2[((match2['team1_id'] == team_id) | (match2['team2_id'] == team_id)) & 
                          (match2['match_dt'] < match_date) & 
                          (match2['lighting'] == lighting_condition)]
    team_matches = team_matches.sort_values(by='match_dt', ascending=False).head(5)
    return team_matches


def calculate_win_percentage(team_id, matches):
    if len(matches) == 0:
        return np.NaN
    win_count = 0
    for _, match in matches.iterrows():
        if (match['team1_id'] == team_id and match['winner_id'] == match['team1_id']) or \
           (match['team2_id'] == team_id and match['winner_id'] == match['team2_id']):
            win_count += 1
    win_percentage = win_count / len(matches)
    return win_percentage


day_night_ratios=[]
for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    lighting_condition = row['lighting']
    
    team1_matches = get_last_5_matches_with_lighting(team1_id, match_date, lighting_condition, match_lvl_data)
    team2_matches = get_last_5_matches_with_lighting(team2_id, match_date, lighting_condition, match_lvl_data)
    
    team1_win_percentage = calculate_win_percentage(team1_id, team1_matches)
    team2_win_percentage = calculate_win_percentage(team2_id, team2_matches)
    
    # First match logic
    if (len(team1_matches) == 0) or (len(team2_matches) == 0):
        ratio = 0.5
        
    elif(len(team1_matches)==0):
        ratio = row['percent_won_first_match']
      
    elif(len(team2_matches)==0):
        ratio = 1-row['percent_won_first_match']  
       
    else:
        ratio = ((team1_win_percentage * 50) + 1) / (((team2_win_percentage * 50) + 1)+((team1_win_percentage * 50) + 1))
    
    day_night_ratios.append(ratio)

train_data['day_night_match'] = day_night_ratios


train_data['day_night_match'] = day_night_ratios


train_data.head()


createRnP(train_data, 'day_night_match')


day_night_ratios=[]
for index, row in test_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    lighting_condition = row['lighting']
    
    team1_matches = get_last_5_matches_with_lighting(team1_id, match_date, lighting_condition, match_lvl_data)
    team2_matches = get_last_5_matches_with_lighting(team2_id, match_date, lighting_condition, match_lvl_data)
    
    team1_win_percentage = calculate_win_percentage(team1_id, team1_matches)
    team2_win_percentage = calculate_win_percentage(team2_id, team2_matches)
    
    # First match logic
    if (len(team1_matches) == 0) or (len(team2_matches) == 0):
        ratio = 0.5
        
    elif(len(team1_matches)==0):
        ratio = row['percent_won_first_match']
      
    elif(len(team2_matches)==0):
        ratio = 1-row['percent_won_first_match']  
       
    else:
        ratio = ((team1_win_percentage * 50) + 1) / (((team2_win_percentage * 50) + 1)+((team1_win_percentage * 50) + 1))
    
    day_night_ratios.append(ratio)

test_data['day_night_match'] = day_night_ratios


test_data.head()





# Function to get the last 5 matches where a team batted first
def get_last_10_matches_batting_first(team_id, match_date, match_data):
    team_matches = match_data[((match_data['team1_id'] == team_id) | (match_data['team2_id'] == team_id)) & 
                              (match_data['match_dt'] < match_date) & 
                              ((match_data['team1_id'] == team_id) & (match_data['toss_decision_01'] == 1) |
                               (match_data['team2_id'] == team_id) & (match_data['toss_decision_01'] == 1))]
    team_matches = team_matches.sort_values(by='match_dt', ascending=False).head(10)
    return team_matches


# Function to get the last 5 matches where a team bowled first
def get_last_10_matches_bowling_first(team_id, match_date, match_data):
    team_matches = match_data[((match_data['team1_id'] == team_id) | (match_data['team2_id'] == team_id)) & 
                              (match_data['match_dt'] < match_date) & 
                              ((match_data['team1_id'] == team_id) & (match_data['toss_decision_01'] == 0) |
                               (match_data['team2_id'] == team_id) & (match_data['toss_decision_01'] == 0))]
    team_matches = team_matches.sort_values(by='match_dt', ascending=False).head(10)
    return team_matches


# Function to calculate win percentage
def calculate_win_percentage(team_id, matches):
    if len(matches) == 0:
        return np.NaN
    win_count = 0
    for _, match in matches.iterrows():
        if (match['team1_id'] == team_id and match['winner_id'] == match['team1_id']) or \
           (match['team2_id'] == team_id and match['winner_id'] == match['team2_id']):
            win_count += 1
    win_percentage = win_count / len(matches)
    return win_percentage


# Initialize the new feature list
batting_bowling_ratios = []

for index, row in train_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    toss_winner_01 = row['toss_winner_01']  # 0 if team1 won the toss, 1 if team2 won the toss
    toss_decision_01 = row['toss_decision_01']  # 1 if batting is chosen, 0 if bowling is chosen
    
    # Determine team IDs of toss winner and loser
    if toss_winner_01 == 0:
        toss_winner_id = team1_id
        toss_loser_id = team2_id
    else:
        toss_winner_id = team2_id
        toss_loser_id = team1_id

    if toss_decision_01 == 1:  # Toss winner chooses to bat
        batting_first_team_id = toss_winner_id
        bowling_first_team_id = toss_loser_id
    else:  # Toss winner chooses to bowl
        batting_first_team_id = toss_loser_id
        bowling_first_team_id = toss_winner_id

    # Get last 5 matches for each team
    batting_first_matches = get_last_10_matches_batting_first(batting_first_team_id, match_date, match_lvl_data)
    bowling_first_matches = get_last_10_matches_bowling_first(bowling_first_team_id, match_date, match_lvl_data)
    
    # Calculate win percentages
    batting_first_win_percentage = calculate_win_percentage(batting_first_team_id, batting_first_matches)
    bowling_first_win_percentage = calculate_win_percentage(bowling_first_team_id, bowling_first_matches)
    
    # First match logic
    if (len(batting_first_matches) == 0) or (len(bowling_first_matches) == 0):
        ratio = 0.5
    elif len(batting_first_matches) == 0:
        ratio = row['percent_won_first_match']
    elif len(bowling_first_matches) == 0:
        ratio = 1 - row['percent_won_first_match']
    else:
        ratio = ((batting_first_win_percentage * 50) + 1) / ((bowling_first_win_percentage * 50) + 1)
    
    batting_bowling_ratios.append(ratio)

# Add the new feature to the train_data dataframe
train_data['batting_bowling_win_ratio'] = batting_bowling_ratios


train_data.head()


createRnP(train_data, 'batting_bowling_win_ratio')


# Initialize the new feature list
batting_bowling_ratios = []

for index, row in test_data.iterrows():
    match_id = row['match id']
    team1_id = row['team1_id']
    team2_id = row['team2_id']
    match_date = row['match_dt']
    toss_winner_01 = row['toss_winner_01']  # 0 if team1 won the toss, 1 if team2 won the toss
    toss_decision_01 = row['toss_decision_01']  # 1 if batting is chosen, 0 if bowling is chosen
    
    # Determine team IDs of toss winner and loser
    if toss_winner_01 == 0:
        toss_winner_id = team1_id
        toss_loser_id = team2_id
    else:
        toss_winner_id = team2_id
        toss_loser_id = team1_id

    if toss_decision_01 == 1:  # Toss winner chooses to bat
        batting_first_team_id = toss_winner_id
        bowling_first_team_id = toss_loser_id
    else:  # Toss winner chooses to bowl
        batting_first_team_id = toss_loser_id
        bowling_first_team_id = toss_winner_id

    # Get last 5 matches for each team
    batting_first_matches = get_last_10_matches_batting_first(batting_first_team_id, match_date, match_lvl_data)
    bowling_first_matches = get_last_10_matches_bowling_first(bowling_first_team_id, match_date, match_lvl_data)
    
    # Calculate win percentages
    batting_first_win_percentage = calculate_win_percentage(batting_first_team_id, batting_first_matches)
    bowling_first_win_percentage = calculate_win_percentage(bowling_first_team_id, bowling_first_matches)
    
    # First match logic
    if (len(batting_first_matches) == 0) or (len(bowling_first_matches) == 0):
        ratio = 0.5
    elif len(batting_first_matches) == 0:
        ratio = row['percent_won_first_match']
    elif len(bowling_first_matches) == 0:
        ratio = 1 - row['percent_won_first_match']
    else:
        ratio = ((batting_first_win_percentage * 50) + 1) / ((bowling_first_win_percentage * 50) + 1)
    
    batting_bowling_ratios.append(ratio)

# Add the new feature to the train_data dataframe
test_data['batting_bowling_win_ratio'] = batting_bowling_ratios





def teamAvgRunsLastn(team_id, date, n):
   
    df_rel = match_lvl_data[(match_lvl_data['match_dt'] < date) & \
                            ((match_lvl_data['team1_id'] == team_id) | (match_lvl_data['team2_id'] == team_id))] \
                            .sort_values(by='match_dt', ascending=False).head(n)
    
    df_rel = pd.concat([df_rel[df_rel['team1_id'] == team_id][['inning1_runs']].rename(columns={'inning1_runs': 'runs'}),
                        df_rel[df_rel['team2_id'] == team_id][['inning2_runs']].rename(columns={'inning2_runs': 'runs'})])
    
    return df_rel['runs'].mean()


# Compute average runs scored by team1 in their last 15 games for train data.
train_data['team1only_avg_runs_last15'] = train_data.progress_apply(
    lambda x: teamAvgRunsLastn(x['team1_id'], x['match_dt'], 15), axis=1)



# Compute average runs scored by team2 in their last 15 games for train data.
train_data['team2only_avg_runs_last15'] = train_data.progress_apply(
    lambda x: teamAvgRunsLastn(x['team2_id'], x['match_dt'], 15), axis=1)




# Calculate the ratio of average runs
train_data['ratio_avg_runs_last15'] = train_data['team1only_avg_runs_last15'] / train_data['team2only_avg_runs_last15']

# Handle infinite values resulting from division by zero
train_data['ratio_avg_runs_last15'].replace([np.inf, -np.inf], np.nan, inplace=True)


createRnP(train_data, 'ratio_avg_runs_last15')


# Compute average runs scored by team1 in their last 15 games for train data.
test_data['team1only_avg_runs_last15'] = test_data.progress_apply(
    lambda x: teamAvgRunsLastn(x['team1_id'], x['match_dt'], 15), axis=1)



# Compute average runs scored by team2 in their last 15 games for train data.
test_data['team2only_avg_runs_last15'] = test_data.progress_apply(
    lambda x: teamAvgRunsLastn(x['team2_id'], x['match_dt'], 15), axis=1)



# Calculate the ratio of average runs
test_data['ratio_avg_runs_last15'] = test_data['team1only_avg_runs_last15'] / test_data['team2only_avg_runs_last15']

# Handle infinite values resulting from division by zero
test_data['ratio_avg_runs_last15'].replace([np.inf, -np.inf], np.nan, inplace=True)





from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from catboost import CatBoostClassifier
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK
from sklearn.feature_selection import mutual_info_classif
from statsmodels.stats.outliers_influence import variance_inflation_factor


'''We Combined Mutual Information with Multicollinearity Checks to get the top features and used it below. 
Commented the not so important features.'''


X,y = train_data[[#'toss_winner_01',
                  #'toss_decision_01',
                  'team_count_50runs_last15',
                  'team_winp_last5',
                  #'team1only_avg_runs_last15',
                  'team1_winp_team2_last15',
                  'ground_avg_runs_last15',
                  #'team_avg_Econ_last10',
                  #'pitch condition',
                  #'percentage_dot_balls_bowled_last_5',
                  'team_wickets_ratio_last10',
                  #'percentage_runs_through_boundaries_last_5_ratio',
                  'team_runs_ratio_last10',
                  'ratio_avg_runs_last15',
                  'team_srrate_ratio_last10', 
                  #'team_avg_econ_ratio_last10', 
                  #'runs_through_extras_last_5_ratio', 
                  #'ratio_avg_runs_last15',
                  'bowling_srrate_ratio_last_10', 
                  #'day_night_match',
                  #'batting_bowling_win_ratio'
                  'weighted wins']], train_data['winner_01']


X_test = test_data[X.columns.tolist()]





from sklearn.impute import KNNImputer
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report


#I divided the dataset into three parts: training, feature selection, and testing. 
#This approach allows for unbiased feature selection and parameter tuning, leading to a more accurate and generalizable model.


'''# Split the data into training, feature selection, and testing datasets
X_train_full, X_feature_selection, y_train_full, y_feature_selection = train_test_split(
    X_imputed_df, y, test_size=0.2, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)'''


from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)





'''# Initialize the KNNImputer
imputer = KNNImputer(n_neighbors=5)

# Fit and transform the training features
X_imputed = imputer.fit_transform(X)

# Transform the test features
X_test_imputed = imputer.transform(X_test[feature_columns])'''


'''# Convert the imputed arrays back to DataFrames
X_imputed_df = pd.DataFrame(X_imputed, columns=feature_columns)
X_test_imputed_df = pd.DataFrame(X_test_imputed, columns=feature_columns)

# Add 'team1_id', 'team2_id', 'match id' back to X_test_imputed_df
X_test_imputed_df[id_columns] = X_test[id_columns].reset_index(drop=True)'''


'''# Verify if there are any remaining missing values
print("Training data missing values after imputation:")
print(X_imputed_df.isna().sum())

print("Test data missing values after imputation:")
print(X_test_imputed_df.isna().sum())'''


# X_imputed_df.head()





# Identify columns with missing values in X_train
X_train_nans = X_train.isna().sum().reset_index()
print("Columns with missing values in X_train:")
print(X_train_nans[X_train_nans[0] != 0])

# Identify columns with missing values in X_test
X_test_nans = X_test.isna().sum().reset_index()
print("Columns with missing values in X_test:")
print(X_test_nans[X_test_nans[0] != 0])

# Impute missing values (replace NaNs with 0)
X_train.fillna(0, inplace=True)
X_test.fillna(0, inplace=True)
X_val.fillna(0,inplace=True)
# Confirm no more missing values in X_train
X_train_nans_after = X_train.isna().sum().reset_index()
print("Columns with missing values in X_train after imputation:")
print(X_train_nans_after[X_train_nans_after[0] != 0])

# Confirm no more missing values in X_test
X_test_nans_after = X_test.isna().sum().reset_index()
print("Columns with missing values in X_test after imputation:")
print(X_test_nans_after[X_test_nans_after[0] != 0])





# Calculate and print descriptive statistics for each specified feature
features = [
    #'toss_winner_01',
                  #'toss_decision_01',
                  'team_count_50runs_last15',
                  'team_winp_last5',
                  #'team1only_avg_runs_last15',
                  'team1_winp_team2_last15',
                  'ground_avg_runs_last15',
                  #'team_avg_Econ_last10',
                  #'pitch condition',
                  #'percentage_dot_balls_bowled_last_5',
                  'team_wickets_ratio_last10',
                  #'percentage_runs_through_boundaries_last_5_ratio',
                  'team_runs_ratio_last10',
                  'ratio_avg_runs_last15',
                  'team_srrate_ratio_last10', 
                  #'team_avg_econ_ratio_last10', 
                  #'runs_through_extras_last_5_ratio', 
                  #'ratio_avg_runs_last15',
                  'bowling_srrate_ratio_last_10', 
                  #'day_night_match',
                  #'batting_bowling_win_ratio'
                  'weighted wins'
]

# Print descriptive statistics for each feature
for feature in features:
    print(f"Descriptive statistics for {feature}:")
    print(X_train[feature].describe(), "\n")
    print(X_test[feature].describe(), "\n")
    print(X_val[feature].describe(), "\n")








# We Combined Mutual Information with Multicollinearity Checks to get the top features and used it. 
# Commented the not so important features while selecting relevant columns.


# Step 2: Feature Selection Combining Mutual Information with Multicollinearity Checks
mutual_info = mutual_info_classif(X_feature_selection, y_feature_selection)
mi_series = pd.Series(mutual_info, index=feature_columns)
top_features_mi = mi_series.nlargest(10).index.tolist()


def calculate_vif(X):
    vif_data = pd.DataFrame()
    vif_data["feature"] = X.columns
    vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
    return vif_data


# Adjust the threshold to ensure we have at least 10 features
vif_threshold = 10
vif_filtered_features = []

while len(vif_filtered_features) < 10 and vif_threshold >= 1:
    vif_data = calculate_vif(X_feature_selection[top_features_mi])
    vif_filtered_features = vif_data[vif_data["VIF"] < vif_threshold]["feature"].tolist()
    vif_threshold -= 1

# If fewer than 10 features are still present, forcefully select top 10 features regardless of VIF
if len(vif_filtered_features) < 10:
    vif_filtered_features = vif_data.sort_values(by="VIF").head(10)["feature"].tolist()

print(f"Selected features: {vif_filtered_features}")





# We tried Combining RFE and Cross-Validation but results were not nice. 


from sklearn.model_selection import StratifiedKFold
import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from xgboost import XGBClassifier
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score


'''# Step 2: Feature Selection with RFE and Cross-Validation
from sklearn.model_selection import StratifiedKFold

# Define the XGBoost model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

# Define RFE with cross-validation
n_features_to_select = 10
rfe = RFE(estimator=xgb_model, n_features_to_select=n_features_to_select, step=1)
rfe = rfe.fit(X_scaled_df, y)

# Get the selected features
selected_features = X_scaled_df.columns[rfe.support_].tolist()
print(f"Selected Features: {selected_features}")'''


'''# Perform cross-validation to evaluate the performance of the selected features
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(xgb_model, X_scaled_df[selected_features], y, cv=cv, scoring='accuracy')
print(f"Cross-Validation Accuracy Scores: {scores}")
print(f"Mean CV Accuracy: {scores.mean()}")'''





from sklearn.impute import KNNImputer
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import VotingClassifier
from lightgbm import LGBMClassifier
from sklearn.feature_selection import RFE
from catboost import CatBoostClassifier
from sklearn.feature_selection import mutual_info_classif
import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor





from xgboost import XGBClassifier
from sklearn.metrics import classification_report


# These paramentes below are taken by trying with both BayesianOptimization and GridSearchCV and then choosing the best one


# User-defined parameters
algo_name = 'XGBClassifier'
is_ensemble = 'no'
n_trees = 13
depth = 2
lr = 0.17





clf_xgb = XGBClassifier(
    n_estimators=n_trees,
    max_depth=depth,
    learning_rate=lr,
    use_label_encoder=False,
    eval_metric='logloss'
).fit(X, y)


# Predict on training and test data
train_data['y_pred_01'] = clf_xgb.predict(X)
test_data['y_pred_01'] = clf_xgb.predict(X_test)


# Train accuracy
print(classification_report(y, clf_xgb.predict(X), labels=[0, 1]))


# Predict probabilities
train_data['win_pred_score'] = clf_xgb.predict_proba(X)[:, 1]
test_data['win_pred_score'] = clf_xgb.predict_proba(X_test)[:, 1]





train_data['win_pred_score'] = np.where(
    train_data['y_pred_01'] == 0, 
    1 - train_data['win_pred_score'], 
    train_data['win_pred_score']
)
test_data['win_pred_score'] = np.where(
    test_data['y_pred_01'] == 0, 
    1 - test_data['win_pred_score'], 
    test_data['win_pred_score']
)





train_data['win_pred_team_id'] = np.where(
    train_data['y_pred_01'] == 0, 
    train_data['team1_id'], 
    train_data['team2_id']
)
test_data['win_pred_team_id'] = np.where(
    test_data['y_pred_01'] == 0, 
    test_data['team1_id'], 
    test_data['team2_id']
)





df_feat_importance = pd.DataFrame({
    'feat_name': X.columns.tolist(), 
    'model_feat_imp_train': clf_xgb.feature_importances_
}).sort_values(by='model_feat_imp_train', ascending=False).reset_index(drop=True).head(10)

df_feat_importance


# We used  BayesianOptimization and GridSearchCV to get the best hyperparameters and then compared the model accuracy using both results





from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import SelectKBest
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from bayes_opt import BayesianOptimization
import statsmodels.api as sm


# Hyperparameter tuning using Bayesian Optimization
def objective(params):
    clf = XGBClassifier(
        n_estimators=int(params['n_estimators']),
        max_depth=int(params['max_depth']),
        learning_rate=params['learning_rate'],
        use_label_encoder=False,
        eval_metric='logloss'
    )
    clf.fit(X_train[vif_filtered_features], y_train)
    preds = clf.predict(X_val[vif_filtered_features])
    accuracy = accuracy_score(y_val, preds)
    return {'loss': -accuracy, 'status': STATUS_OK}

space = {
    'n_estimators': hp.quniform('n_estimators', 10, 100, 1),
    'max_depth': hp.quniform('max_depth', 1, 10, 1),
    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3)
}

trials = Trials()
best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials)
best_params['n_estimators'] = int(best_params['n_estimators'])
best_params['max_depth'] = int(best_params['max_depth'])


# Train final model using best hyperparameters
clf_xgb = XGBClassifier(
    n_estimators=best_params['n_estimators'],
    max_depth=best_params['max_depth'],
    learning_rate=best_params['learning_rate'],
    use_label_encoder=False,
    eval_metric='logloss'
)
clf_xgb.fit(X_train[vif_filtered_features], y_train)


# Predict on training, validation, and test data
train_pred = clf_xgb.predict(X_train[vif_filtered_features])
val_pred = clf_xgb.predict(X_val[vif_filtered_features])
test_pred = clf_xgb.predict(X_test_imputed_df[vif_filtered_features])

# Evaluate model
print("Train Classification Report:")
print(classification_report(y_train, train_pred, labels=[0, 1]))
print("Validation Classification Report:")
print(classification_report(y_val, val_pred, labels=[0, 1]))


# Combine training, validation, and feature selection sets into a single training set
X_combined = pd.concat([X_train, X_val, X_feature_selection])
y_combined = pd.concat([y_train, y_val, y_feature_selection])

# Train the final model on the combined training set
clf_xgb.fit(X_combined[vif_filtered_features], y_combined)


# Predict on combined training data and test data
train_combined_pred = clf_xgb.predict(X_combined[vif_filtered_features])
test_pred = clf_xgb.predict(X_test_imputed_df[vif_filtered_features])

# Ensure length consistency before assigning predictions
train_data_copy = train_data.loc[X_combined.index].copy()
test_data_copy = test_data.copy()

train_data_copy['y_pred_01'] = train_combined_pred
test_data_copy['y_pred_01'] = test_pred


# Predict probabilities
train_data_copy['win_pred_score'] = clf_xgb.predict_proba(X_combined[vif_filtered_features])[:, 1]
test_data_copy['win_pred_score'] = clf_xgb.predict_proba(X_test_imputed_df[vif_filtered_features])[:, 1]


# Adjust win_pred_score for the winning team
train_data_copy['win_pred_score'] = np.where(
    train_data_copy['y_pred_01'] == 0,
    1 - train_data_copy['win_pred_score'],
    train_data_copy['win_pred_score']
)
test_data_copy['win_pred_score'] = np.where(
    test_data_copy['y_pred_01'] == 0,
    1 - test_data_copy['win_pred_score'],
    test_data_copy['win_pred_score']
)


# Determine winner_team_id from custom dependent column
train_data_copy['win_pred_team_id'] = np.where(
    train_data_copy['y_pred_01'] == 0,
    train_data_copy['team1_id'],
    train_data_copy['team2_id']
)
test_data_copy['win_pred_team_id'] = np.where(
    test_data_copy['y_pred_01'] == 0,
    test_data_copy['team1_id'],
    test_data_copy['team2_id']
)


# Feature importance
df_feat_importance = pd.DataFrame({
    'feat_name': vif_filtered_features,
    'model_feat_imp_train': clf_xgb.feature_importances_
}).sort_values(by='model_feat_imp_train', ascending=False).reset_index(drop=True).head(10)

df_feat_importance





# Step 3: Hyperparameter Tuning with Grid Search
from sklearn.model_selection import GridSearchCV

# Define parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2]
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=2)
grid_search.fit(X_scaled_df[selected_features], y)

# Get the best parameters
best_params = grid_search.best_params_
print(f"Best Parameters: {best_params}")


# Train the final model with the best parameters
final_model = XGBClassifier(
    n_estimators=best_params['n_estimators'],
    max_depth=best_params['max_depth'],
    learning_rate=best_params['learning_rate'],
    use_label_encoder=False,
    eval_metric='logloss'
)
final_model.fit(X_scaled_df[selected_features], y)


# Step 4: Model Evaluation
# Predict on the test set
test_pred = final_model.predict(X_test_scaled_df[selected_features])

# Check if 'winner_01' is in test_data to calculate accuracy
if target_column in test_data.columns:
    # Calculate accuracy on the test set
    test_accuracy = accuracy_score(test_data[target_column], test_pred)
    print(f"Test Accuracy: {test_accuracy}")
else:
    print(f"Column '{target_column}' not found in test data. Cannot calculate test accuracy.")


# Feature importance
df_feat_importance = pd.DataFrame({
    'feat_name': selected_features,
    'model_feat_imp_train': final_model.feature_importances_
}).sort_values(by='model_feat_imp_train', ascending=False).reset_index(drop=True).head(10)

# Prepare submission DataFrame
train_data_copy = train_data.copy()
test_data_copy = test_data.copy()

train_data_copy['win_pred_score'] = final_model.predict_proba(X_scaled_df[selected_features])[:, 1]
test_data_copy['win_pred_score'] = final_model.predict_proba(X_test_scaled_df[selected_features])[:, 1]

# Determine winner_team_id from custom dependent column
train_data_copy['win_pred_team_id'] = np.where(
    train_data_copy['win_pred_score'] >= 0.5,
    train_data_copy['team2_id'],
    train_data_copy['team1_id']
)
test_data_copy['win_pred_team_id'] = np.where(
    test_data_copy['win_pred_score'] >= 0.5,
    test_data_copy['team2_id'],
    test_data_copy['team1_id']
)


# We got the best results using XgBoost but below are a list of all other algorithms we tried





from catboost import CatBoostClassifier
from sklearn.metrics import classification_report


# User-defined parameters
algo_name = 'CatBoostClassifier'
is_ensemble = 'no'
n_trees = 96
depth = 3
lr = 0.027425083650459835


# Initialize and train the CatBoost model on the training set
clf_catboost = CatBoostClassifier(
    iterations=n_trees,
    depth=depth,
    learning_rate=lr,
    eval_metric='Logloss',
    verbose=0
)
clf_catboost.fit(X_train, y_train)


# Predict on training and validation data
train_pred = clf_catboost.predict(X_train)
val_pred = clf_catboost.predict(X_val)


# Train and validation accuracy
print("Train Classification Report:")
print(classification_report(y_train, train_pred, labels=[0, 1]))
print("Validation Classification Report:")
print(classification_report(y_val, val_pred, labels=[0, 1]))


# Combine training and validation sets into a single training set
X_combined = pd.concat([X_train, X_val])
y_combined = pd.concat([y_train, y_val])

# Train the final model on the combined training set
clf_catboost.fit(X_combined, y_combined)

# Predict on combined training data and test data
train_combined_pred = clf_catboost.predict(X_combined)
test_pred = clf_catboost.predict(X_test)

# Ensure length consistency before assigning predictions
train_data_copy = train_data.loc[X_combined.index].copy()
test_data_copy = test_data.copy()

train_data_copy['y_pred_01'] = train_combined_pred
test_data_copy['y_pred_01'] = test_pred


# Predict probabilities
train_data_copy['win_pred_score'] = clf_catboost.predict_proba(X_combined)[:, 1]
test_data_copy['win_pred_score'] = clf_catboost.predict_proba(X_test)[:, 1]


# Adjust win_pred_score for the winning team
train_data_copy['win_pred_score'] = np.where(
    train_data_copy['y_pred_01'] == 0,
    1 - train_data_copy['win_pred_score'],
    train_data_copy['win_pred_score']
)
test_data_copy['win_pred_score'] = np.where(
    test_data_copy['y_pred_01'] == 0,
    1 - test_data_copy['win_pred_score'],
    test_data_copy['win_pred_score']
)


# Determine winner_team_id from custom dependent column
train_data_copy['win_pred_team_id'] = np.where(
    train_data_copy['y_pred_01'] == 0,
    train_data_copy['team1_id'],
    train_data_copy['team2_id']
)
test_data_copy['win_pred_team_id'] = np.where(
    test_data_copy['y_pred_01'] == 0,
    test_data_copy['team1_id'],
    test_data_copy['team2_id']
)


# Feature importance
df_feat_importance = pd.DataFrame({
    'feat_name': X_combined.columns.tolist(),
    'model_feat_imp_train': clf_catboost.get_feature_importance()
}).sort_values(by='model_feat_imp_train', ascending=False).reset_index(drop=True).head(10)

df_feat_importance





# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import accuracy_score, classification_report
from catboost import CatBoostClassifier
from sklearn.feature_selection import mutual_info_classif
from statsmodels.stats.outliers_influence import variance_inflation_factor
from scipy.stats import uniform, randint


# Define the parameter grid for RandomizedSearchCV
param_dist = {
    'iterations': randint(10, 100),
    'depth': randint(1, 10),
    'learning_rate': uniform(0.01, 0.3)
}

# Initialize the CatBoostClassifier
clf_catboost = CatBoostClassifier(eval_metric='Logloss', verbose=0)

# Initialize RandomizedSearchCV
random_search = RandomizedSearchCV(
    clf_catboost, param_distributions=param_dist, n_iter=50, cv=3, verbose=1, n_jobs=-1, random_state=42
)

# Fit RandomizedSearchCV
random_search.fit(X_train[vif_filtered_features], y_train)

# Get the best parameters
best_params = random_search.best_params_
print(f"Best parameters found: {best_params}")


# Train final model using best hyperparameters
clf_catboost = CatBoostClassifier(
    iterations=best_params['iterations'],
    depth=best_params['depth'],
    learning_rate=best_params['learning_rate'],
    eval_metric='Logloss',
    verbose=0
)
clf_catboost.fit(X_train[vif_filtered_features], y_train)


print(best_params)


# Predict on training, validation, and test data
train_pred = clf_catboost.predict(X_train[vif_filtered_features])
val_pred = clf_catboost.predict(X_val[vif_filtered_features])
test_pred = clf_catboost.predict(X_test_imputed_df[vif_filtered_features])

# Evaluate model
print("Train Classification Report:")
print(classification_report(y_train, train_pred, labels=[0, 1]))
print("Validation Classification Report:")
print(classification_report(y_val, val_pred, labels=[0, 1]))


# Combine training, validation, and feature selection sets into a single training set
X_combined = pd.concat([X_train, X_val, X_feature_selection])
y_combined = pd.concat([y_train, y_val, y_feature_selection])

# Train the final model on the combined training set
clf_catboost.fit(X_combined[vif_filtered_features], y_combined)


# Predict on combined training data and test data
train_combined_pred = clf_catboost.predict(X_combined[vif_filtered_features])
test_pred = clf_catboost.predict(X_test_imputed_df[vif_filtered_features])

# Ensure length consistency before assigning predictions
train_data_copy = train_data.loc[X_combined.index].copy()
test_data_copy = test_data.copy()

train_data_copy['y_pred_01'] = train_combined_pred
test_data_copy['y_pred_01'] = test_pred


# Predict probabilities
train_data_copy['win_pred_score'] = clf_catboost.predict_proba(X_combined[vif_filtered_features])[:, 1]
test_data_copy['win_pred_score'] = clf_catboost.predict_proba(X_test_imputed_df[vif_filtered_features])[:, 1]


# Adjust win_pred_score for the winning team
train_data_copy['win_pred_score'] = np.where(
    train_data_copy['y_pred_01'] == 0,
    1 - train_data_copy['win_pred_score'],
    train_data_copy['win_pred_score']
)
test_data_copy['win_pred_score'] = np.where(
    test_data_copy['y_pred_01'] == 0,
    1 - test_data_copy['win_pred_score'],
    test_data_copy['win_pred_score']
)


# Determine winner_team_id from custom dependent column
train_data_copy['win_pred_team_id'] = np.where(
    train_data_copy['y_pred_01'] == 0,
    train_data_copy['team1_id'],
    train_data_copy['team2_id']
)
test_data_copy['win_pred_team_id'] = np.where(
    test_data_copy['y_pred_01'] == 0,
    test_data_copy['team1_id'],
    test_data_copy['team2_id']
)


# Feature importance
df_feat_importance = pd.DataFrame({
    'feat_name': vif_filtered_features,
    'model_feat_imp_train': clf_catboost.get_feature_importance()
}).sort_values(by='model_feat_imp_train', ascending=False).reset_index(drop=True).head(10)

df_feat_importance





from sklearn.ensemble import GradientBoostingClassifier


# user-defined parameters

algo_name = 'GradientBoostingClassifier'
is_ensemble = 'no'
n_trees = 10
depth = 2
lr = 0.1





clf_gbm = GradientBoostingClassifier(n_estimators = n_trees, max_depth = depth, learning_rate = lr).fit(X,y)


train_data['y_pred_01'] = clf_gbm.predict(X)
test_data['y_pred_01'] = clf_gbm.predict(X_test)


from sklearn.metrics import classification_report


# Train accuracy
print(classification_report(y, clf_gbm.predict(X), labels=[0,1]))


train_data['win_pred_score'] = clf_gbm.predict_proba(X)[:,1]
test_data['win_pred_score'] = clf_gbm.predict_proba(X_test)[:,1]





train_data['win_pred_score'] = np.where( (train_data['y_pred_01']==0), (1-train_data['win_pred_score']), train_data['win_pred_score'])
test_data['win_pred_score'] = np.where( (test_data['y_pred_01']==0), (1-test_data['win_pred_score']), test_data['win_pred_score'])





train_data['win_pred_team_id'] = np.where( (train_data['y_pred_01']==0), (train_data['team1_id']), train_data['team2_id'])
test_data['win_pred_team_id'] = np.where( (test_data['y_pred_01']==0), (test_data['team1_id']), test_data['team2_id'])





df_feat_importance = pd.DataFrame({'feat_name':X.columns.tolist(), 'model_feat_imp_train':clf_gbm.feature_importances_}).sort_values(by='model_feat_imp_train', ascending=False)\
                                                                                                                        .reset_index(drop=True).head(10)
df_feat_importance





from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report


# User-defined parameters
algo_name = 'LGBMClassifier'
is_ensemble = 'no'
n_trees = 13
depth = 2
lr = 0.17


# Initialize and train the model
clf_lgbm = LGBMClassifier(
    n_estimators=n_trees,
    max_depth=depth,
    learning_rate=lr,
    objective='binary'
).fit(X, y)


# Predict on training and test data
train_data['y_pred_01'] = clf_lgbm.predict(X)
test_data['y_pred_01'] = clf_lgbm.predict(X_test)


# Train accuracy
print(classification_report(y, clf_lgbm.predict(X), labels=[0, 1]))


# Predict probabilities
train_data['win_pred_score'] = clf_lgbm.predict_proba(X)[:, 1]
test_data['win_pred_score'] = clf_lgbm.predict_proba(X_test)[:, 1]


train_data['win_pred_score'] = np.where(
    train_data['y_pred_01'] == 0, 
    1 - train_data['win_pred_score'], 
    train_data['win_pred_score']
)
test_data['win_pred_score'] = np.where(
    test_data['y_pred_01'] == 0, 
    1 - test_data['win_pred_score'], 
    test_data['win_pred_score']
)


train_data['win_pred_team_id'] = np.where(
    train_data['y_pred_01'] == 0, 
    train_data['team1_id'], 
    train_data['team2_id']
)
test_data['win_pred_team_id'] = np.where(
    test_data['y_pred_01'] == 0, 
    test_data['team1_id'], 
    test_data['team2_id']
)


df_feat_importance = pd.DataFrame({
    'feat_name': X.columns.tolist(), 
    'model_feat_imp_train': clf_lgbm.feature_importances_
}).sort_values(by='model_feat_imp_train', ascending=False).reset_index(drop=True).head(10)

df_feat_importance








# For File 1
train_data['dataset_type'] = 'train'
test_data['dataset_type'] = 'r1'


## refactor

df_file1 = pd.concat([test_data[['match id','dataset_type','win_pred_team_id','win_pred_score',] + list(df_feat_importance['feat_name'].head(10))], \
                     train_data[['match id','dataset_type','win_pred_team_id','win_pred_score',] + list(df_feat_importance['feat_name'].head(10))]])

renaming_dict = {}
for i,col in enumerate(list(df_feat_importance['feat_name'].head(10))):
    renaming_dict[col] = f'indep_feat_id{i+1}'
df_file1.rename(columns=renaming_dict, inplace=True)

for i in range(1,11):
    if f'indep_feat_id{i}' not in df_file1.columns:
        df_file1[f'indep_feat_id{i}'] = np.nan

df_file1['train_algorithm'] = algo_name
df_file1['is_ensemble'] = is_ensemble
df_file1['train_hps_trees'] = n_trees
df_file1['train_hps_depth'] = depth
df_file1['train_hps_lr'] = lr


df_file1.shape
df_file1.head()





feature_desc = {
    'team_count_50runs_last15': 'Ratio of number of 50s by players in team1 to number of 50s by players in team2 in last 15 games',
    'team_winp_last5': 'Ratio of team1\'s win % to team2\'s win % in last 5 games',
    'ground_avg_runs_last15': 'Average runs scored in the ground in last 15 games',
    'team1_winp_team2_last15': 'Team1\'s win percentage against Team2 in last 15 games',
    'team1only_avg_runs_last15': 'Team1\'s average inning runs in last 15 games',
    'season_num': 'Numerical form of season. Takes 1 for oldest season and increases for latest seasons.',
    'toss_winner_01': 'Toss winner to numerical - 1 if team2 wins, else 0',
    'toss_decision_01': 'Toss decision - categorical - 1 if winner bats, 0 otherwise',
    'team_avg_Econ_last10': 'Ratio of team\'s average inning economy ratio in last 10 games',
    'team_srrate_ratio_last10': 'Ratio of the average weighted strike rate of the top 3 batsmen in the last 10 games',
    'team_runs_ratio_last10': 'Ratio of runs scored by top 3 batsmen of both teams',
    'percentage_dot_balls_bowled_last_5': 'Ratio of percentage of dot balls bowled by each team in the last 5 games',
    'pitch condition': 'Who\'s winning - chasing team or defending team',
    'team_wickets_ratio_last10': 'Ratio of number of wickets taken by the top 3 bowlers in the roster of a team in the last 10 games',
    'percentage_runs_through_boundaries_last_5_ratio': 'Ratio of the runs through boundaries for the two teams in the last 5 games',
    'team_avg_econ_ratio_last10': 'Ratio of the average economy rate of the top 3 bowlers of a team in the last 10 games',
    'runs_through_extras_last_5_ratio': 'Ratio of extras conceded in last 5 games',
    'bowling_srrate_ratio_last_10': 'Bowling strike rate ratio',
    'weighted wins': 'Ratio of weighted average of wins for teams, normalizing win amounts by wickets and runs',
    'day_night_match': 'Ratio of teams performance in Day/Night Conditions',
    'batting_bowling_win_ratio': 'Ratio of win percentage of teams batting/bowling first in last 10 games',
    'ratio_avg_runs_last15': 'Ratio of average runs of both teams in the last 15 matches'
}


# df_feat_importance.rename(index={0:'feat_id'}, inplace=True)
df_file2 = df_feat_importance
df_file2['feat_id'] = [i+1 for i in df_file2.index]
df_file2['feat_rank_train'] = [i+1 for i in df_file2.index]
df_file2 = df_file2.set_index('feat_id')
df_file2['feat_description'] = df_file2['feat_name'].map(feature_desc)


df_file2





df_file1.to_csv('2024_DS_Track_R1_File1_Data Titans.csv', index=False)
df_file2.to_csv('2024_DS_Track_R1_File2_Data Titans.csv')



